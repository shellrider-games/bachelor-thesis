{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02509da-48f0-4f2b-876d-6ac9107f2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862a8f25-29e4-4da9-a3d0-2526e3940562",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43b78e4-d9dd-4349-8cbb-b92de576147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for file in os.listdir(folder):\n",
    "        img = cv.imread(os.path.join(folder,file))\n",
    "        if(img is not None):\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec599119-a0f0-40b9-8829-7552c876743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_flatten(img, target_size=(64,64)):\n",
    "    resized_img = cv.resize(img, target_size)\n",
    "    flattened_img = resized_img.reshape(target_size[0] * target_size[1] * 3)\n",
    "    return flattened_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87dc05ed-a06b-4548-9fba-088b4f374b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = []\n",
    "for img in load_images_from_folder(\"../notebooks/myfirstNN/data/cat\"):\n",
    "    cat_data.append(resize_and_flatten(img))\n",
    "dog_data = []\n",
    "for img in load_images_from_folder(\"../notebooks/myfirstNN/data/dog\"):\n",
    "    dog_data.append(resize_and_flatten(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8af40c-9dfe-4dd8-b1e3-f4bf24b0a4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772 cat images\n",
      "772 dog images\n"
     ]
    }
   ],
   "source": [
    "print(str(len(cat_data)) + \" cat images\")\n",
    "print(str(len(dog_data)) + \" dog images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30be7ae5-67c3-4ffb-87f7-036a3f254510",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for entity in cat_data:\n",
    "    X.append(entity)\n",
    "    y.append(1)\n",
    "\n",
    "for entity in dog_data:\n",
    "    X.append(entity)\n",
    "    y.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac8262b3-2b25-4922-beae-1a2849e232ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(64*64*3, 16*16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16*16, 16*16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16*16, 2)\n",
    "        )\n",
    "    def forward(self, x, **kwargs):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c8ee7f3-4a61-412c-abf9-fd7f1d3f38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    module = MyNN,\n",
    "    max_epochs=10,\n",
    "    lr=0.001,\n",
    "    iterator_train__shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e29ebc8-269f-4f5a-9f54-2ea3e3d93874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GeorgBecker\\AppData\\Local\\Temp\\ipykernel_20252\\3442304046.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  gs.fit(torch.FloatTensor(X), torch.LongTensor(y))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.0381\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1835\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.0096\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1661\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.8538\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1681\n",
      "      2        7.9583       0.4968        8.0226  0.1575\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.6843\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1585\n",
      "      2        7.9583       0.4968        8.0226  0.1901\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9941\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1672\n",
      "      2        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1783\n",
      "      3        7.9841       0.5032        7.9198  0.1632\n",
      "      4        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1771\n",
      "      5        7.9841       0.5032        7.9198  0.1605\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9840\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.5442\u001b[0m  0.1665\n",
      "      2        8.0540       0.4968        8.0226  0.1600\n",
      "      3        \u001b[36m7.9583\u001b[0m       0.4968        8.0226  0.2201\n",
      "      4        \u001b[36m7.9583\u001b[0m       0.4968        8.0226  0.2061\n",
      "      5        \u001b[36m7.9583\u001b[0m       0.4968        8.0226  0.1631\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m6.8650\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1621\n",
      "      2        7.9841       0.5032        7.9198  0.1637\n",
      "      3        7.9841       0.5032        7.9198  0.1615\n",
      "      4        7.9841       0.5032        7.9198  0.1651\n",
      "      5        7.9841       0.5032        7.9198  0.1565\n",
      "      6        7.9841       0.5032        7.9198  0.1675\n",
      "      7        7.9841       0.5032        7.9198  0.1581\n",
      "      8        7.9841       0.5032        7.9198  0.1695\n",
      "      9        7.9841       0.5032        7.9198  0.1615\n",
      "     10        7.9841       0.5032        7.9198  0.1671\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9508\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1610\n",
      "      2        7.9583       0.4968        8.0226  0.1595\n",
      "      3        7.9583       0.4968        8.0226  0.1686\n",
      "      4        7.9583       0.4968        8.0226  0.1621\n",
      "      5        7.9583       0.4968        8.0226  0.1745\n",
      "      6        7.9583       0.4968        8.0226  0.1620\n",
      "      7        7.9583       0.4968        8.0226  0.1641\n",
      "      8        7.9583       0.4968        8.0226  0.1657\n",
      "      9        7.9583       0.4968        8.0226  0.1581\n",
      "     10        7.9583       0.4968        8.0226  0.1671\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9841\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1591\n",
      "      2        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1621\n",
      "      3        7.9841       0.5032        7.9198  0.1640\n",
      "      4        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1631\n",
      "      5        7.9841       0.5032        7.9198  0.1871\n",
      "      6        7.9841       0.5032        7.9198  0.1685\n",
      "      7        7.9841       0.5032        7.9198  0.1591\n",
      "      8        7.9841       0.5032        7.9198  0.1641\n",
      "      9        7.9841       0.5032        7.9198  0.1615\n",
      "     10        7.9841       0.5032        7.9198  0.1711\n",
      "     11        7.9841       0.5032        7.9198  0.1661\n",
      "     12        7.9841       0.5032        7.9198  0.1675\n",
      "     13        7.9841       0.5032        7.9198  0.1551\n",
      "     14        7.9841       0.5032        7.9198  0.1710\n",
      "     15        7.9841       0.5032        7.9198  0.1685\n",
      "     16        7.9841       0.5032        7.9198  0.1610\n",
      "     17        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1731\n",
      "     18        7.9841       0.5032        7.9198  0.1645\n",
      "     19        7.9841       0.5032        7.9198  0.1670\n",
      "     20        7.9841       0.5032        7.9198  0.1601\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9687\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1591\n",
      "      2        \u001b[36m7.9583\u001b[0m       0.4968        8.0226  0.1595\n",
      "      3        7.9583       0.4968        8.0226  0.1640\n",
      "      4        7.9583       0.4968        8.0226  0.1571\n",
      "      5        7.9583       0.4968        8.0226  0.1715\n",
      "      6        7.9583       0.4968        8.0226  0.1691\n",
      "      7        7.9583       0.4968        8.0226  0.1710\n",
      "      8        7.9583       0.4968        8.0226  0.1715\n",
      "      9        7.9583       0.4968        8.0226  0.1601\n",
      "     10        7.9583       0.4968        8.0226  0.1710\n",
      "     11        7.9583       0.4968        8.0226  0.1575\n",
      "     12        7.9583       0.4968        8.0226  0.1728\n",
      "     13        7.9583       0.4968        8.0226  0.1622\n",
      "     14        7.9583       0.4968        8.0226  0.1671\n",
      "     15        7.9583       0.4968        8.0226  0.1765\n",
      "     16        7.9583       0.4968        8.0226  0.1620\n",
      "     17        7.9583       0.4968        8.0226  0.1670\n",
      "     18        7.9583       0.4968        8.0226  0.1675\n",
      "     19        7.9583       0.4968        8.0226  0.1680\n",
      "     20        7.9583       0.4968        8.0226  0.1657\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.5421\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1670\n",
      "      2        7.9583       0.4968        8.0226  0.1565\n",
      "      3        7.9583       0.4968        8.0226  0.1640\n",
      "      4        7.9583       0.4968        8.0226  0.1651\n",
      "      5        7.9583       0.4968        8.0226  0.1695\n",
      "      6        7.9583       0.4968        8.0226  0.1660\n",
      "      7        7.9583       0.4968        8.0226  0.1712\n",
      "      8        7.9583       0.4968        8.0226  0.1661\n",
      "      9        7.9583       0.4968        8.0226  0.1615\n",
      "     10        7.9583       0.4968        8.0226  0.1731\n",
      "     11        7.9583       0.4968        8.0226  0.1650\n",
      "     12        7.9583       0.4968        8.0226  0.1695\n",
      "     13        7.9583       0.4968        8.0226  0.1697\n",
      "     14        7.9583       0.4968        8.0226  0.1616\n",
      "     15        7.9583       0.4968        8.0226  0.1645\n",
      "     16        7.9583       0.4968        8.0226  0.1559\n",
      "     17        7.9583       0.4968        8.0226  0.1680\n",
      "     18        7.9583       0.4968        8.0226  0.1705\n",
      "     19        7.9583       0.4968        8.0226  0.1701\n",
      "     20        7.9583       0.4968        8.0226  0.1581\n",
      "     21        7.9583       0.4968        8.0226  0.1691\n",
      "     22        7.9583       0.4968        8.0226  0.1640\n",
      "     23        7.9583       0.4968        8.0226  0.1591\n",
      "     24        7.9583       0.4968        8.0226  0.1635\n",
      "     25        7.9583       0.4968        8.0226  0.1711\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m8.3208\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1511\n",
      "      2        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1681\n",
      "      3        7.9841       0.5032        7.9198  0.1695\n",
      "      4        7.9841       0.5032        7.9198  0.1690\n",
      "      5        7.9841       0.5032        7.9198  0.1720\n",
      "      6        7.9841       0.5032        7.9198  0.1605\n",
      "      7        7.9841       0.5032        7.9198  0.1660\n",
      "      8        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1641\n",
      "      9        7.9841       0.5032        7.9198  0.1605\n",
      "     10        7.9841       0.5032        7.9198  0.1640\n",
      "     11        7.9841       0.5032        7.9198  0.1601\n",
      "     12        7.9841       0.5032        7.9198  0.1685\n",
      "     13        7.9841       0.5032        7.9198  0.1618\n",
      "     14        7.9841       0.5032        7.9198  0.1691\n",
      "     15        7.9841       0.5032        7.9198  0.1625\n",
      "     16        7.9841       0.5032        7.9198  0.1710\n",
      "     17        7.9841       0.5032        7.9198  0.1691\n",
      "     18        7.9841       0.5032        7.9198  0.1585\n",
      "     19        7.9841       0.5032        7.9198  0.1695\n",
      "     20        7.9841       0.5032        7.9198  0.1631\n",
      "     21        7.9841       0.5032        7.9198  0.1700\n",
      "     22        7.9841       0.5032        7.9198  0.1665\n",
      "     23        7.9841       0.5032        7.9198  0.1609\n",
      "     24        7.9841       0.5032        7.9198  0.1630\n",
      "     25        7.9841       0.5032        7.9198  0.1655\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m8.0332\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1575\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9841\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1641\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m6.9528\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1625\n",
      "      2        7.9841       0.5032        7.9198  0.1820\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9841\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1665\n",
      "      2        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1630\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9841\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1610\n",
      "      2        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1631\n",
      "      3        7.9841       0.5032        7.9198  0.1595\n",
      "      4        7.9841       0.5032        7.9198  0.1610\n",
      "      5        7.9841       0.5032        7.9198  0.1595\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m6.9870\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1616\n",
      "      2        7.9583       0.4968        8.0226  0.1660\n",
      "      3        7.9583       0.4968        8.0226  0.1580\n",
      "      4        7.9583       0.4968        8.0226  0.1675\n",
      "      5        7.9583       0.4968        8.0226  0.1641\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9841\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1585\n",
      "      2        7.9841       0.5032        7.9198  0.1691\n",
      "      3        7.9841       0.5032        7.9198  0.1615\n",
      "      4        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1641\n",
      "      5        7.9841       0.5032        7.9198  0.1650\n",
      "      6        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1685\n",
      "      7        7.9841       0.5032        7.9198  0.1615\n",
      "      8        7.9841       0.5032        7.9198  0.1723\n",
      "      9        7.9841       0.5032        7.9198  0.1681\n",
      "     10        7.9841       0.5032        7.9198  0.1655\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m6.9124\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1581\n",
      "      2        7.9583       0.4968        8.0226  0.1731\n",
      "      3        7.9583       0.4968        8.0226  0.1601\n",
      "      4        7.9583       0.4968        8.0226  0.1595\n",
      "      5        7.9583       0.4968        8.0226  0.1571\n",
      "      6        7.9583       0.4968        8.0226  0.1821\n",
      "      7        7.9583       0.4968        8.0226  0.1622\n",
      "      8        7.9583       0.4968        8.0226  0.1751\n",
      "      9        7.9583       0.4968        8.0226  0.1611\n",
      "     10        7.9583       0.4968        8.0226  0.1605\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.3800\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1566\n",
      "      2        7.9583       0.4968        8.0226  0.1685\n",
      "      3        7.9583       0.4968        8.0226  0.1611\n",
      "      4        7.9583       0.4968        8.0226  0.1651\n",
      "      5        7.9583       0.4968        8.0226  0.1555\n",
      "      6        7.9583       0.4968        8.0226  0.1701\n",
      "      7        7.9583       0.4968        8.0226  0.1655\n",
      "      8        7.9583       0.4968        8.0226  0.1641\n",
      "      9        7.9583       0.4968        8.0226  0.1731\n",
      "     10        7.9583       0.4968        8.0226  0.1776\n",
      "     11        7.9583       0.4968        8.0226  0.1745\n",
      "     12        7.9583       0.4968        8.0226  0.1675\n",
      "     13        7.9583       0.4968        8.0226  0.1591\n",
      "     14        7.9583       0.4968        8.0226  0.1731\n",
      "     15        7.9583       0.4968        8.0226  0.2661\n",
      "     16        7.9583       0.4968        8.0226  0.1761\n",
      "     17        7.9583       0.4968        8.0226  0.1620\n",
      "     18        7.9583       0.4968        8.0226  0.1725\n",
      "     19        7.9583       0.4968        8.0226  0.1590\n",
      "     20        7.9583       0.4968        8.0226  0.1991\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m8.1897\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1695\n",
      "      2        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1661\n",
      "      3        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1611\n",
      "      4        7.9841       0.5032        7.9198  0.1655\n",
      "      5        7.9841       0.5032        7.9198  0.1630\n",
      "      6        7.9841       0.5032        7.9198  0.1730\n",
      "      7        7.9841       0.5032        7.9198  0.1898\n",
      "      8        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1565\n",
      "      9        7.9841       0.5032        7.9198  0.1741\n",
      "     10        7.9841       0.5032        7.9198  0.1601\n",
      "     11        7.9841       0.5032        7.9198  0.1821\n",
      "     12        7.9841       0.5032        7.9198  0.1685\n",
      "     13        7.9841       0.5032        7.9198  0.1671\n",
      "     14        7.9841       0.5032        7.9198  0.1761\n",
      "     15        7.9841       0.5032        7.9198  0.1675\n",
      "     16        7.9841       0.5032        7.9198  0.1751\n",
      "     17        7.9841       0.5032        7.9198  0.1678\n",
      "     18        7.9841       0.5032        7.9198  0.1631\n",
      "     19        7.9841       0.5032        7.9198  0.1745\n",
      "     20        7.9841       0.5032        7.9198  0.1724\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.5607\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1761\n",
      "      2        7.9583       0.4968        8.0226  0.1609\n",
      "      3        7.9583       0.4968        8.0226  0.1695\n",
      "      4        7.9583       0.4968        8.0226  0.1625\n",
      "      5        7.9583       0.4968        8.0226  0.1659\n",
      "      6        7.9583       0.4968        8.0226  0.1671\n",
      "      7        7.9583       0.4968        8.0226  0.1625\n",
      "      8        7.9583       0.4968        8.0226  0.1651\n",
      "      9        7.9583       0.4968        8.0226  0.1615\n",
      "     10        7.9583       0.4968        8.0226  0.1776\n",
      "     11        7.9583       0.4968        8.0226  0.1651\n",
      "     12        7.9583       0.4968        8.0226  0.1700\n",
      "     13        7.9583       0.4968        8.0226  0.1666\n",
      "     14        7.9583       0.4968        8.0226  0.1597\n",
      "     15        7.9583       0.4968        8.0226  0.1746\n",
      "     16        7.9583       0.4968        8.0226  0.1605\n",
      "     17        7.9583       0.4968        8.0226  0.1706\n",
      "     18        7.9583       0.4968        8.0226  0.1690\n",
      "     19        7.9583       0.4968        8.0226  0.1635\n",
      "     20        7.9583       0.4968        8.0226  0.1705\n",
      "     21        7.9583       0.4968        8.0226  0.1831\n",
      "     22        7.9583       0.4968        8.0226  0.1601\n",
      "     23        7.9583       0.4968        8.0226  0.1645\n",
      "     24        7.9583       0.4968        8.0226  0.1620\n",
      "     25        7.9583       0.4968        8.0226  0.1671\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.4605\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1676\n",
      "      2        7.9841       0.5032        7.9198  0.1685\n",
      "      3        7.9841       0.5032        7.9198  0.1625\n",
      "      4        7.9841       0.5032        7.9198  0.1671\n",
      "      5        7.9841       0.5032        7.9198  0.1595\n",
      "      6        7.9841       0.5032        7.9198  0.1750\n",
      "      7        7.9841       0.5032        7.9198  0.1584\n",
      "      8        7.9841       0.5032        7.9198  0.1691\n",
      "      9        7.9841       0.5032        7.9198  0.1685\n",
      "     10        7.9841       0.5032        7.9198  0.1630\n",
      "     11        7.9841       0.5032        7.9198  0.1710\n",
      "     12        7.9841       0.5032        7.9198  0.1555\n",
      "     13        7.9841       0.5032        7.9198  0.1715\n",
      "     14        7.9841       0.5032        7.9198  0.1650\n",
      "     15        7.9841       0.5032        7.9198  0.1665\n",
      "     16        7.9841       0.5032        7.9198  0.1591\n",
      "     17        7.9841       0.5032        7.9198  0.1650\n",
      "     18        7.9841       0.5032        7.9198  0.1615\n",
      "     19        7.9841       0.5032        7.9198  0.1621\n",
      "     20        7.9841       0.5032        7.9198  0.1660\n",
      "     21        7.9841       0.5032        7.9198  0.1645\n",
      "     22        7.9841       0.5032        7.9198  0.1680\n",
      "     23        7.9841       0.5032        7.9198  0.1690\n",
      "     24        7.9841       0.5032        7.9198  0.1665\n",
      "     25        7.9841       0.5032        7.9198  0.1640\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.3484\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1645\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.0988\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1615\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.1645\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1545\n",
      "      2        7.9583       0.4968        8.0226  0.1596\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m8.3005\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1591\n",
      "      2        \u001b[36m7.9583\u001b[0m       0.4968        8.0226  0.1695\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m6.9521\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1655\n",
      "      2        7.9583       0.4968        8.0226  0.1630\n",
      "      3        7.9583       0.4968        8.0226  0.1660\n",
      "      4        7.9583       0.4968        8.0226  0.1766\n",
      "      5        7.9583       0.4968        8.0226  0.1755\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m6.7047\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1701\n",
      "      2        7.9583       0.4968        8.0226  0.1936\n",
      "      3        7.9583       0.4968        8.0226  0.2017\n",
      "      4        7.9583       0.4968        8.0226  0.1994\n",
      "      5        7.9583       0.4968        8.0226  0.1791\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.8259\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1749\n",
      "      2        7.9841       0.5032        7.9198  0.1725\n",
      "      3        7.9841       0.5032        7.9198  0.1620\n",
      "      4        7.9841       0.5032        7.9198  0.1781\n",
      "      5        7.9841       0.5032        7.9198  0.1751\n",
      "      6        7.9841       0.5032        7.9198  0.1725\n",
      "      7        7.9841       0.5032        7.9198  0.1781\n",
      "      8        7.9841       0.5032        7.9198  0.1821\n",
      "      9        7.9841       0.5032        7.9198  0.1761\n",
      "     10        7.9841       0.5032        7.9198  0.1741\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9841\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1675\n",
      "      2        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1741\n",
      "      3        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1732\n",
      "      4        7.9841       0.5032        7.9198  0.1726\n",
      "      5        7.9841       0.5032        7.9198  0.1708\n",
      "      6        7.9841       0.5032        7.9198  0.1661\n",
      "      7        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1675\n",
      "      8        7.9841       0.5032        7.9198  0.1710\n",
      "      9        7.9841       0.5032        7.9198  0.1610\n",
      "     10        7.9841       0.5032        7.9198  0.1665\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.8042\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m8.0226\u001b[0m  0.1585\n",
      "      2        7.9583       0.4968        8.0226  0.1591\n",
      "      3        7.9583       0.4968        8.0226  0.1611\n",
      "      4        7.9583       0.4968        8.0226  0.1595\n",
      "      5        7.9583       0.4968        8.0226  0.1691\n",
      "      6        7.9583       0.4968        8.0226  0.1621\n",
      "      7        7.9583       0.4968        8.0226  0.1705\n",
      "      8        7.9583       0.4968        8.0226  0.1610\n",
      "      9        7.9583       0.4968        8.0226  0.1641\n",
      "     10        7.9583       0.4968        8.0226  0.1625\n",
      "     11        7.9583       0.4968        8.0226  0.1641\n",
      "     12        7.9583       0.4968        8.0226  0.1701\n",
      "     13        7.9583       0.4968        8.0226  0.1636\n",
      "     14        7.9583       0.4968        8.0226  0.1737\n",
      "     15        7.9583       0.4968        8.0226  0.1901\n",
      "     16        7.9583       0.4968        8.0226  0.1606\n",
      "     17        7.9583       0.4968        8.0226  0.1675\n",
      "     18        7.9583       0.4968        8.0226  0.1591\n",
      "     19        7.9583       0.4968        8.0226  0.1731\n",
      "     20        7.9583       0.4968        8.0226  0.1605\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m6.8936\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1555\n",
      "      2        7.9841       0.5032        7.9198  0.1646\n",
      "      3        7.9841       0.5032        7.9198  0.1681\n",
      "      4        7.9841       0.5032        7.9198  0.1555\n",
      "      5        7.9841       0.5032        7.9198  0.1701\n",
      "      6        7.9841       0.5032        7.9198  0.1526\n",
      "      7        7.9841       0.5032        7.9198  0.1629\n",
      "      8        7.9841       0.5032        7.9198  0.1631\n",
      "      9        7.9841       0.5032        7.9198  0.1781\n",
      "     10        7.9841       0.5032        7.9198  0.1695\n",
      "     11        7.9841       0.5032        7.9198  0.1601\n",
      "     12        7.9841       0.5032        7.9198  0.1662\n",
      "     13        7.9841       0.5032        7.9198  0.1655\n",
      "     14        7.9841       0.5032        7.9198  0.1751\n",
      "     15        7.9841       0.5032        7.9198  0.1521\n",
      "     16        7.9841       0.5032        7.9198  0.1721\n",
      "     17        7.9841       0.5032        7.9198  0.1701\n",
      "     18        7.9841       0.5032        7.9198  0.1621\n",
      "     19        7.9841       0.5032        7.9198  0.1785\n",
      "     20        7.9841       0.5032        7.9198  0.1635\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9841\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1580\n",
      "      2        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1680\n",
      "      3        7.9841       0.5032        7.9198  0.1710\n",
      "      4        7.9841       0.5032        7.9198  0.1584\n",
      "      5        7.9841       0.5032        7.9198  0.2446\n",
      "      6        7.9841       0.5032        7.9198  0.1711\n",
      "      7        7.9841       0.5032        7.9198  0.1763\n",
      "      8        7.9841       0.5032        7.9198  0.1661\n",
      "      9        7.9841       0.5032        7.9198  0.1696\n",
      "     10        7.9841       0.5032        7.9198  0.1745\n",
      "     11        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1631\n",
      "     12        7.9841       0.5032        7.9198  0.1701\n",
      "     13        7.9841       0.5032        7.9198  0.1745\n",
      "     14        7.9841       0.5032        7.9198  0.1641\n",
      "     15        7.9841       0.5032        7.9198  0.1769\n",
      "     16        7.9841       0.5032        7.9198  0.1741\n",
      "     17        7.9841       0.5032        7.9198  0.1635\n",
      "     18        7.9841       0.5032        7.9198  0.1761\n",
      "     19        7.9841       0.5032        7.9198  0.1791\n",
      "     20        7.9841       0.5032        7.9198  0.1651\n",
      "     21        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1675\n",
      "     22        7.9841       0.5032        7.9198  0.1637\n",
      "     23        7.9841       0.5032        7.9198  0.1751\n",
      "     24        7.9841       0.5032        7.9198  0.1585\n",
      "     25        7.9841       0.5032        7.9198  0.1706\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9841\u001b[0m       \u001b[32m0.5032\u001b[0m        \u001b[35m7.9198\u001b[0m  0.1588\n",
      "      2        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1641\n",
      "      3        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1615\n",
      "      4        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1621\n",
      "      5        \u001b[36m7.9841\u001b[0m       0.5032        7.9198  0.1601\n",
      "      6        7.9841       0.5032        7.9198  0.1714\n",
      "      7        7.9841       0.5032        7.9198  0.1626\n",
      "      8        7.9841       0.5032        7.9198  0.1671\n",
      "      9        7.9841       0.5032        7.9198  0.1666\n",
      "     10        7.9841       0.5032        7.9198  0.1631\n",
      "     11        7.9841       0.5032        7.9198  0.1741\n",
      "     12        7.9841       0.5032        7.9198  0.1635\n",
      "     13        7.9841       0.5032        7.9198  0.1695\n",
      "     14        7.9841       0.5032        7.9198  0.1721\n",
      "     15        7.9841       0.5032        7.9198  0.1891\n",
      "     16        7.9841       0.5032        7.9198  0.1595\n",
      "     17        7.9841       0.5032        7.9198  0.1615\n",
      "     18        7.9841       0.5032        7.9198  0.1689\n",
      "     19        7.9841       0.5032        7.9198  0.1813\n",
      "     20        7.9841       0.5032        7.9198  0.1675\n",
      "     21        7.9841       0.5032        7.9198  0.1555\n",
      "     22        7.9841       0.5032        7.9198  0.1682\n",
      "     23        7.9841       0.5032        7.9198  0.1681\n",
      "     24        7.9841       0.5032        7.9198  0.1920\n",
      "     25        7.9841       0.5032        7.9198  0.1811\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.6253\u001b[0m       \u001b[32m0.4984\u001b[0m        \u001b[35m7.9970\u001b[0m  0.3478\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>param_max_epochs</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.448120</td>\n",
       "      <td>0.245060</td>\n",
       "      <td>0.101263</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001, 'max_epochs': 1}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.377616</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>0.114369</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>{'lr': 0.001, 'max_epochs': 2}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.927323</td>\n",
       "      <td>0.033956</td>\n",
       "      <td>0.106033</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>{'lr': 0.001, 'max_epochs': 5}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.691104</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.097534</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'lr': 0.001, 'max_epochs': 10}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.397450</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.101313</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>{'lr': 0.001, 'max_epochs': 20}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.226117</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.108528</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>{'lr': 0.001, 'max_epochs': 25}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.196088</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.106305</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.01, 'max_epochs': 1}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.373567</td>\n",
       "      <td>0.009522</td>\n",
       "      <td>0.101026</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>{'lr': 0.01, 'max_epochs': 2}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.854408</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.107523</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>{'lr': 0.01, 'max_epochs': 5}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.709612</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.111687</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{'lr': 0.01, 'max_epochs': 10}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.514028</td>\n",
       "      <td>0.036629</td>\n",
       "      <td>0.109036</td>\n",
       "      <td>0.013512</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>{'lr': 0.01, 'max_epochs': 20}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.251555</td>\n",
       "      <td>0.022208</td>\n",
       "      <td>0.110043</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{'lr': 0.01, 'max_epochs': 25}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.197543</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.100525</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.0001, 'max_epochs': 1}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.356642</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>0.105024</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>{'lr': 0.0001, 'max_epochs': 2}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.947282</td>\n",
       "      <td>0.051081</td>\n",
       "      <td>0.111791</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>{'lr': 0.0001, 'max_epochs': 5}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.780125</td>\n",
       "      <td>0.026175</td>\n",
       "      <td>0.110528</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'lr': 0.0001, 'max_epochs': 10}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.385188</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.105036</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>{'lr': 0.0001, 'max_epochs': 20}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.345105</td>\n",
       "      <td>0.041759</td>\n",
       "      <td>0.105530</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>25</td>\n",
       "      <td>{'lr': 0.0001, 'max_epochs': 25}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lr  \\\n",
       "0        0.448120      0.245060         0.101263        0.005737    0.001   \n",
       "1        0.377616      0.012029         0.114369        0.002839    0.001   \n",
       "2        0.927323      0.033956         0.106033        0.002507    0.001   \n",
       "3        1.691104      0.006544         0.097534        0.002997    0.001   \n",
       "4        3.397450      0.001918         0.101313        0.002207    0.001   \n",
       "5        4.226117      0.008344         0.108528        0.004001    0.001   \n",
       "6        0.196088      0.005051         0.106305        0.001787     0.01   \n",
       "7        0.373567      0.009522         0.101026        0.005497     0.01   \n",
       "8        0.854408      0.003202         0.107523        0.005000     0.01   \n",
       "9        1.709612      0.002512         0.111687        0.002861     0.01   \n",
       "10       3.514028      0.036629         0.109036        0.013512     0.01   \n",
       "11       4.251555      0.022208         0.110043        0.006510     0.01   \n",
       "12       0.197543      0.003495         0.100525        0.000003   0.0001   \n",
       "13       0.356642      0.005009         0.105024        0.001502   0.0001   \n",
       "14       0.947282      0.051081         0.111791        0.003267   0.0001   \n",
       "15       1.780125      0.026175         0.110528        0.014000   0.0001   \n",
       "16       3.385188      0.005086         0.105036        0.000498   0.0001   \n",
       "17       4.345105      0.041759         0.105530        0.003003   0.0001   \n",
       "\n",
       "   param_max_epochs                            params  split0_test_score  \\\n",
       "0                 1    {'lr': 0.001, 'max_epochs': 1}                0.5   \n",
       "1                 2    {'lr': 0.001, 'max_epochs': 2}                0.5   \n",
       "2                 5    {'lr': 0.001, 'max_epochs': 5}                0.5   \n",
       "3                10   {'lr': 0.001, 'max_epochs': 10}                0.5   \n",
       "4                20   {'lr': 0.001, 'max_epochs': 20}                0.5   \n",
       "5                25   {'lr': 0.001, 'max_epochs': 25}                0.5   \n",
       "6                 1     {'lr': 0.01, 'max_epochs': 1}                0.5   \n",
       "7                 2     {'lr': 0.01, 'max_epochs': 2}                0.5   \n",
       "8                 5     {'lr': 0.01, 'max_epochs': 5}                0.5   \n",
       "9                10    {'lr': 0.01, 'max_epochs': 10}                0.5   \n",
       "10               20    {'lr': 0.01, 'max_epochs': 20}                0.5   \n",
       "11               25    {'lr': 0.01, 'max_epochs': 25}                0.5   \n",
       "12                1   {'lr': 0.0001, 'max_epochs': 1}                0.5   \n",
       "13                2   {'lr': 0.0001, 'max_epochs': 2}                0.5   \n",
       "14                5   {'lr': 0.0001, 'max_epochs': 5}                0.5   \n",
       "15               10  {'lr': 0.0001, 'max_epochs': 10}                0.5   \n",
       "16               20  {'lr': 0.0001, 'max_epochs': 20}                0.5   \n",
       "17               25  {'lr': 0.0001, 'max_epochs': 25}                0.5   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                 0.5              0.5             0.0                1  \n",
       "1                 0.5              0.5             0.0                1  \n",
       "2                 0.5              0.5             0.0                1  \n",
       "3                 0.5              0.5             0.0                1  \n",
       "4                 0.5              0.5             0.0                1  \n",
       "5                 0.5              0.5             0.0                1  \n",
       "6                 0.5              0.5             0.0                1  \n",
       "7                 0.5              0.5             0.0                1  \n",
       "8                 0.5              0.5             0.0                1  \n",
       "9                 0.5              0.5             0.0                1  \n",
       "10                0.5              0.5             0.0                1  \n",
       "11                0.5              0.5             0.0                1  \n",
       "12                0.5              0.5             0.0                1  \n",
       "13                0.5              0.5             0.0                1  \n",
       "14                0.5              0.5             0.0                1  \n",
       "15                0.5              0.5             0.0                1  \n",
       "16                0.5              0.5             0.0                1  \n",
       "17                0.5              0.5             0.0                1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {    \n",
    "    'lr': [0.001, 0.01, 0.0001],\n",
    "    'max_epochs': [1,2,5, 10, 20, 25],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, params, cv=2)\n",
    "gs.fit(torch.FloatTensor(X), torch.LongTensor(y))\n",
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4aa41a8-5fdb-4cec-8f0f-e1a618372f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = load_images_from_folder(\"../notebooks/myfirstNN/data/cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87efd0b8-4769-4fe1-86b8-1bdd3b32cd29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c33a1-e7ae-4978-b25f-53b1d5e6d439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
